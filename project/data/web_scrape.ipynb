{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making my movie and tv show recommendations site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0: Import necessary packages to scrape my IMDB lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scrape Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening HTML file localy\n",
    "HTMLFileToBeOpened = open(\"movies_source.html\", \"r\")\n",
    "# Reading the file and storing it in a variable\n",
    "contents = HTMLFileToBeOpened.read()\n",
    "# Creating beautifulsoup object and specifying the parser\n",
    "SoupText = BeautifulSoup(contents, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL you want to fetch\n",
    "m_url = \"https://www.imdb.com/list/ls521504128/?ref_=otl_2\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(m_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the HTML content of the page\n",
    "    movies_contents = response.text\n",
    "    \n",
    "    # Create a BeautifulSoup object and specify the parser\n",
    "    SoupText = BeautifulSoup(movies_contents, 'lxml')\n",
    "    \n",
    "    # Now you can work with the parsed HTML content\n",
    "    # (e.g., extract data or navigate the DOM)\n",
    "    \n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigsoup = SoupText.find('div', {'class': 'lister-list'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the Titles\n",
    "titles = []\n",
    "\n",
    "for h3 in bigsoup.find_all('h3', class_='lister-item-header'):\n",
    "    titles.append(h3.a.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_out = []\n",
    "# Scraping the year it went out\n",
    "for year in bigsoup.find_all('span', class_='lister-item-year'):\n",
    "    year_out.append(year.get_text(strip=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = []\n",
    "# Scraping duration of film\n",
    "for duration in bigsoup.find_all('span', class_='runtime'):\n",
    "    runtime.append(duration.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = []\n",
    "# Scraping the description\n",
    "for summary in bigsoup.find_all('p',class_=''):\n",
    "    description.append(summary.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = []\n",
    "# Scraping genres\n",
    "for movie_genre in bigsoup.find_all('span', class_='genre'):\n",
    "    genre.append(movie_genre.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors = []\n",
    "# Extract director names using list comprehension and filter out empty strings\n",
    "directors = [director.a.string.strip() for director in bigsoup.find_all('p', class_='text-muted') if director.a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract star names\n",
    "star_elements = bigsoup.select('.text-muted.text-small a[href^=\"/name/\"]')\n",
    "\n",
    "# Extract the text (star names)\n",
    "stars = [star.string.strip() for star in star_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for img in bigsoup.find_all('img', class_='loadlate'):\n",
    "    loadlate = img.get('loadlate')\n",
    "    if loadlate:\n",
    "        images.append(loadlate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the lists\n",
    "data = {\n",
    "    \"titles\": titles,\n",
    "    \"year_released\": year_out,\n",
    "    \"runtime\": runtime,\n",
    "    \"description\": description,\n",
    "    \"genres\": genre,\n",
    "    # \"directors\": directors,\n",
    "    \"images\": images\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "movies_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named series_df and want to replace a value in the 'titles' column\n",
    "movies_df['titles'][0] = movies_df['titles'][0].replace('بين النجوم','Interstellar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save my dataframe into a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder path where you want to save the CSV file\n",
    "folder_path = 'csv'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Define the full path to the CSV file\n",
    "csv_file_path = os.path.join(folder_path, 'movies.csv')\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "movies_df.to_csv(csv_file_path, index=False)  # Set index=False to exclude the DataFrame index in the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL you want to fetch\n",
    "url = \"https://www.imdb.com/list/ls521599999/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the HTML content of the page\n",
    "    series_contents = response.text\n",
    "    \n",
    "    # Create a BeautifulSoup object and specify the parser\n",
    "    series_bigsoup = BeautifulSoup(series_contents, 'lxml')\n",
    "    \n",
    "    # Now you can work with the parsed HTML content\n",
    "    # (e.g., extract data or navigate the DOM)\n",
    "    \n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the tv show list on IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening HTML file localy\n",
    "series_html = open(\"/Users/joaquinortega/code/joaquin-ortega84/video-recs/project/data/series_source.html\", \"r\")\n",
    "# Reading the file and storing it in a variable\n",
    "series_contents = series_html.read()\n",
    "# Creating beautifulsoup object and specifying the parser\n",
    "series_bigsoup = BeautifulSoup(series_contents, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_text = series_bigsoup.find('div', {'class': 'lister-list'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the Titles\n",
    "s_titles = []\n",
    "\n",
    "for h3 in series_text.find_all('h3', class_='lister-item-header'):\n",
    "    s_titles.append(h3.a.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_year_out = []\n",
    "# Scraping the year it went out\n",
    "for year in series_text.find_all('span', class_='lister-item-year'):\n",
    "    s_year_out.append(year.get_text(strip=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_runtime = []\n",
    "# Scraping duration of film\n",
    "for duration in series_text.find_all('span', class_='runtime'):\n",
    "    s_runtime.append(duration.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_description = []\n",
    "# Scraping the description\n",
    "for summary in series_text.find_all('p',class_=''):\n",
    "    s_description.append(summary.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_genre = []\n",
    "# Scraping genres\n",
    "for movie_genre in series_text.find_all('span', class_='genre'):\n",
    "    s_genre.append(movie_genre.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_directors = []\n",
    "# Extract director names using list comprehension and filter out empty strings\n",
    "s_directors = [director.a.string.strip() for director in series_text.find_all('p', class_='text-muted') if director.a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract star names\n",
    "s_star_elements = series_text.select('.text-muted.text-small a[href^=\"/name/\"]')\n",
    "\n",
    "# Extract the text (star names)\n",
    "s_stars = [star.string.strip() for star in s_star_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_images = []\n",
    "for img in series_text.find_all('img', class_='loadlate'):\n",
    "    loadlate = img.get('loadlate')\n",
    "    if loadlate:\n",
    "        s_images.append(loadlate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the lists\n",
    "s_data = {\n",
    "    \"titles\": s_titles,\n",
    "    \"year_released\": s_year_out,\n",
    "    \"runtime\": s_runtime,\n",
    "    \"description\": s_description,\n",
    "    \"genres\": s_genre,\n",
    "    # \"directors\": directors,\n",
    "    \"images\": s_images\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "series_df = pd.DataFrame(s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named series_df and want to replace a value in the 'titles' column\n",
    "series_df['titles'][13] = series_df['titles'][13].replace('صراع العروش', 'Game of Thrones')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save my dataframe into a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder path where you want to save the CSV file\n",
    "folder_path = '/Users/joaquinortega/code/joaquin-ortega84/video-recs/project/data/csv'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Define the full path to the CSV file\n",
    "csv_file_path = os.path.join(folder_path, 'series.csv')\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "series_df.to_csv(csv_file_path, index=False)  # Set index=False to exclude the DataFrame index in the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
